{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLatent(latSort,clu=None, n = 2):\n",
    "    for i in range(n):\n",
    "        pyvis.qc_2var(*latSort.T[2*i:2*(i+1)],clu=clu)\n",
    "#         pyvis.qc_2var(*latSort.T[2:4],clu=clu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose(post):\n",
    "    pyvis.heatmap(post.latent.T,)\n",
    "    pyvis.heatmap(post.encoder)\n",
    "\n",
    "    pyvis.heatmap(post.locPer.T)\n",
    "    xs,ys = sutil.meanNorm(train_data),post.locPer\n",
    "    pyvis.qc_2var(xs,ys, )\n",
    "    plt.title(pyutil.mse(xs,ys))\n",
    "\n",
    "    # ims = post.decoder.reshape([-1,8,8])\n",
    "    # arr = post.locPer\n",
    "def showIm(arr,nMax=10):\n",
    "#     arr = post.encoder.T\n",
    "    ims = arr.reshape([-1,8,8])\n",
    "    \n",
    "#     idx = np.argsort(post.latent.std(axis=0),)[::-1]\n",
    "\n",
    "    # ims = pcmd.model.components_.reshape([-1,8,8])\n",
    "#     idx = range(10)\n",
    "    # ims = \n",
    "    # idx= np.where(post.latentScale>0.5)[0]\n",
    "#     print (len(idx))\n",
    "    ims = ims[:nMax]\n",
    "    for Y in ims:\n",
    "        pyvis.heatmap(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is in ipython: 1 \n",
      "[WARN]No module named jinja2_util\n",
      "is in ipython: 1 \n",
      "[WARN]No module named jinja2_util\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] pymisca.vis_util cannot find network\n",
      "[IMPORT] cannot import \"matplotlib_venn\"\n",
      "[WARN] pymisca.vis_util cannot find network\n",
      "[IMPORT] cannot import \"matplotlib_venn\"\n",
      "[FAIL] to process index file:/media/pw_synology3/BrachyPhoton/raw/index, due to [Errno 2] No such file or directory: '/media/pw_synology3/BrachyPhoton/raw/index'\n",
      "[WARN] Cannot find file:key.gene\n",
      "[FAIL] to process index file:/media/pw_synology3/BrachyPhoton/raw/index, due to [Errno 2] No such file or directory: '/media/pw_synology3/BrachyPhoton/raw/index'\n",
      "[WARN] Cannot find file:key.gene\n",
      "[WARN] pymisca.vis_util cannot find network\n",
      "[IMPORT] cannot import \"matplotlib_venn\"\n",
      "[WARN] pymisca.vis_util cannot find network\n",
      "[IMPORT] cannot import \"matplotlib_venn\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is in ipython: 1 \n",
      "[WARN]No module named jinja2_util\n",
      "is in ipython: 1 \n",
      "[WARN]No module named jinja2_util\n"
     ]
    }
   ],
   "source": [
    "import synotil.dio as sdio;reload(sdio)\n",
    "import synotil as synotil; reload(synotil)\n",
    "import synotil.qcplots as pkg; reload(pkg)\n",
    "import synotil.util as sutil;reload(sutil)\n",
    "import synotil.PanelPlot as spanel;reload(spanel)\n",
    "import synotil.CountMatrix as scount;reload(scount)\n",
    "\n",
    "import pymisca.util as pyutil; reload(pyutil)\n",
    "import pymisca.vis_util as pyvis; reload(pyvis)\n",
    "import cPickle as pk\n",
    "\n",
    "testi = 0\n",
    "\n",
    "np = pyutil.np; pd = pyutil.pd\n",
    "plt = pyutil.plt; \n",
    "get_ipython().magic('matplotlib inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymisca.tensorflow_extra_.gamma_radial_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shouldsee/.local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN]unable to import edward.models\n",
      "[WARN]unable to import edward.models\n",
      "[WARN]unable to import edward.models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'pymisca.tensorflow_extra' from '/home/shouldsee/.local/lib/python2.7/site-packages/pymisca/tensorflow_extra.pyc'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modelModule = \"pymisca.tensorflow_extra_.matrix_decomp\"\n",
    "# modelModule = \"pymisca.tensorflow_extra_.affine_gaussian\"\n",
    "modelModule = \"pymisca.tensorflow_extra_.hyper_plane_mixture\"\n",
    "# modelModule = 'pymisca.tensorflow_extra_.gamma_radial_theta'\n",
    "import importlib\n",
    "mym = importlib.import_module(name=modelModule,)\n",
    "reload(mym)\n",
    "\n",
    "import pymisca.tensorflow_extra as pytf; reload(pytf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shouldsee/.local/lib/python2.7/site-packages/sklearn/feature_extraction/hashing.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hashing\n",
      "/home/shouldsee/.local/lib/python2.7/site-packages/scipy/io/matlab/mio4.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .mio_utils import squeeze_element, chars_to_strings\n",
      "/home/shouldsee/.local/lib/python2.7/site-packages/scipy/io/matlab/mio5.py:98: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .mio5_utils import VarReader5\n",
      "/home/shouldsee/.local/lib/python2.7/site-packages/sklearn/datasets/svmlight_format.py:25: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._svmlight_format import _load_svmlight_file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sklearn.datasets as skdat\n",
    "data = skdat.load_digits()\n",
    "data.keys()\n",
    "# all_data = data['data']\n",
    "dfcc=  scount.countMatrix(data['data'])\n",
    "\n",
    "import sklearn.tests as sktest\n",
    "# sktest\n",
    "import sklearn.model_selection as skms\n",
    "kf = skms.KFold(n_splits=3)\n",
    "\n",
    "all_data= dfcc.values\n",
    "all_data = sutil.meanNorm(all_data)\n",
    "# all_data = sutil.meanNorm(all_data.T,).T\n",
    "# all_data = all_data.T\n",
    "train_ind, test_ind = next(kf.split(all_data))\n",
    "train_data = all_data[train_ind]\n",
    "test_data = all_data[test_ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ns.name\n",
    "# dir(ns)\n",
    "# tf.name_sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[testi]=1\n",
      "('reuse', None)\n",
      "('reuse', None)\n",
      "Iter 0 -12517.242\n",
      "Iter 100 -13768.361\n",
      "Iter 200 -35536.496\n",
      "Iter 300 -35726.582\n",
      "Iter 400 -35794.57\n",
      "Iter 500 -35861.348\n",
      "Iter 600 -35928.047\n",
      "Iter 700 -36114.54\n",
      "Iter 800 -40873.17\n",
      "Iter 900 -41081.598\n",
      "Iter 1000 -41467.664\n",
      "Iter 1100 -41786.637\n",
      "Iter 1200 -43029.69\n",
      "Iter 1300 -43378.207\n",
      "Iter 1400 -43800.99\n",
      "Iter 1500 -43914.87\n",
      "Iter 1600 -43981.95\n",
      "Iter 1700 -44051.01\n",
      "Iter 1800 -44189.23\n",
      "Iter 1900 -44234.984\n",
      "Iter 2000 -44272.297\n",
      "Iter 2100 -44306.582\n",
      "Iter 2200 -44337.547\n",
      "Iter 2300 -44366.1\n",
      "Iter 2400 -44393.09\n",
      "Iter 2500 -44419.02\n",
      "Iter 2600 -44444.207\n",
      "Iter 2700 -44468.855\n",
      "Iter 2800 -44493.074\n",
      "Iter 2900 -44516.945\n",
      "[Done]\n",
      "\n",
      "[WARN]unable to import edward.models\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-afb6d9c4b4a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     mdl_post = post = pyutil.util_obj(**{k:pytf.quick_eval(mdl.post[k]) for k in mdl.post.__dict__ \n\u001b[1;32m     49\u001b[0m                                          if k != 'components'})\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# reload(pytf)\n",
    "# reload(mym)\n",
    "reload(mym)\n",
    "_class = mym.main\n",
    "# _class = mym.\n",
    "testi += 1\n",
    "\n",
    "D = train_data.shape[-1]\n",
    "mdls = {}\n",
    "print '[testi]=%d'%testi\n",
    "\n",
    "for seed in range(1):\n",
    "    tf = pytf.tf\n",
    "    tf.set_random_seed(seed+300)\n",
    "\n",
    "\n",
    "    testi+=1\n",
    "    \n",
    "    mdl = _class(D=D,\n",
    "                 L2loss=0.,\n",
    "                 K=35,\n",
    "                 alpha = None,\n",
    "#                  L2loss=1E5,\n",
    "                                  name= 'test_%s'%testi,\n",
    "#                                   mode='gateless',\n",
    "#                                  mode='right',\n",
    "                                 )\n",
    "    TOL_LOSS = 0.1\n",
    "#     opt = tf.train.AdamOptimizer(0.1)\n",
    "    opt = None\n",
    "    #     hist_loss = mdl.fit(train_data,optimizer=opt,n_iter = 2000,TOL_LOSS=TOL_LOSS)\n",
    "    opt = tf.train.AdadeltaOptimizer(0.1)\n",
    "    \n",
    "    hist_loss = mdl.fit(train_data,optimizer=opt,n_iter = 3000,TOL_LOSS=TOL_LOSS)\n",
    "\n",
    "\n",
    "    print ('[Done]')\n",
    "    \n",
    "pyutil.printlines(vars(mdl.prior).values())\n",
    "\n",
    "sess = mdl.sess\n",
    "import pymisca.vis_util as pyvis\n",
    "import pymisca.tensorflow_extra as pytf; reload(pytf)\n",
    "pytf.quick_eval\n",
    "\n",
    "with sess.as_default():\n",
    "#     post = pyutil\n",
    "    mdl_post = post = pyutil.util_obj(**{k:pytf.quick_eval(mdl.post[k]) for k in mdl.post.__dict__ \n",
    "                                         if k != 'components'})\n",
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: modeltest/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.simple_save(mdl.sess,'modeltest',inputs={'x':mdl.x_place},outputs={'y':mdl.proba})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(mdl.sess, \"./testModel.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: ./testModel.ckpt\n"
     ]
    }
   ],
   "source": [
    "print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Later, launch the model, initialize the variables, do some work, and save the\n",
    "# # variables to disk.\n",
    "# with tf.Session() as sess:\n",
    "#   sess.run(init_op)\n",
    "#   # Do some work with the model.\n",
    "#   inc_v1.op.run()\n",
    "#   dec_v2.op.run()\n",
    "#   # Save the variables to disk.\n",
    "#   save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "#   print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "  print(\"Model restored.\")\n",
    "  # Check the values of the variables\n",
    "  print(\"v1 : %s\" % v1.eval())\n",
    "  print(\"v2 : %s\" % v2.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = tf.saved_model.loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = tf.saved_model.loader.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(sorted(post.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "showIm(post.mean[np.argsort(post.weight)[::-1][:10]],nMax=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targ = data['target']\n",
    "test_targ = all_targ[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMat(mdl):\n",
    "    pred_targ = mdl.predict(test_data)\n",
    "\n",
    "    dfc = pd.DataFrame(dict(pred=pred_targ, ground=test_targ))\n",
    "    dfc['num'] = 1\n",
    "    confusion = dfc.pivot_table(index='ground',columns='pred',values='num',aggfunc='sum').fillna(0.)\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_hpm = getConfusionMat(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = sutil.fit_BGM(train_data,nClu=35,covariance_type = 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_GMM = getConfusionMat(mdl.model,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = sutil.fit_KMEANS(train_data,nClu=30)\n",
    "confusion_kmean = getConfusionMat(mdl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvis.heatmap(confusion_kmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvis.heatmap(confusion_hpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.mixture as skmix\n",
    "# skmix.VBGMMx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvis.heatmap(confusion_GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = mdl.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showIm(arr=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clu==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.set_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showIm(train_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skdat.u\n",
    "import sklearn.utils as skutil\n",
    "# skutil.optimizel.\n",
    "# spane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvis.histoLine(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluCount = pyutil.get_cluCount(pd.DataFrame(clu,columns=['clu']))\n",
    "pyutil.ipd.display(cluCount.T)\n",
    "showIm(test_data[clu==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyvis.heatmap(test_data[clu==0],cname='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu = mdl.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clu.query()\n",
    "# cdot = clu[None] == data.target[test_ind][:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "im = pyutil.spdist.squareform(post.scale)\n",
    "pyvis.heatmap(im,cname='scale')\n",
    "\n",
    "im = pyutil.spdist.squareform(post.loc)\n",
    "pyvis.heatmap(im,cname='loc')\n",
    "\n",
    "im = pyutil.spdist.squareform(post.loc/post.scale)\n",
    "pyvis.heatmap(im,cname='loc/scale')\n",
    "# pyvis.heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = sutil.fit_PCA(train_data)\n",
    "post = pyutil.util_obj(**post)\n",
    "post.latent = post.trans_data\n",
    "post.encoder = post.model.components_\n",
    "# post.latent.shape\n",
    "# post.encoder.shape\n",
    "post.locPer = post.latent.dot(post.encoder)\n",
    "pca_post = post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showIm(post.mean[:5],nMax=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "post = mdl_post\n",
    "diagnose(post)\n",
    "\n",
    "showIm(post.locPer[:5],nMax=2)\n",
    "plt.show()\n",
    "print('ttttttttttttt')\n",
    "showIm(post.encoder[:5],nMax=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = mdl.post.mean.eval(session=mdl.sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "post = pca_post\n",
    "diagnose(post)\n",
    "\n",
    "showIm(post.locPer[:5],nMax=2)\n",
    "plt.show()\n",
    "print('ttttttttttttt')\n",
    "showIm(post.encoder[:5],nMax=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sutil.qc_Sort(df=dfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = sutil.meanNorm(test_data)\n",
    "pred = reduce(np.matmul,[C,post.encoder,post.decoder])\n",
    "orig = sutil.meanNorm(C)\n",
    "\n",
    "\n",
    "latent = C.dot(post.encoder)\n",
    "# latent = test_data.dot(post.encoder)\n",
    "xvar = latent.std(axis=0)\n",
    "vidx = xvar.argsort()[::-1]\n",
    "latSort = latent[:,vidx]\n",
    "\n",
    "\n",
    "dfc = reduce(np.matmul,[all_data,post.encoder])[:,vidx]\n",
    "allLatent = dfcc.setDF(dfc)\n",
    "# allLatent = \n",
    "score_all = allLatent.values ** 2\n",
    "score_all = score_all / score_all.sum(axis=1,keepdims=1)\n",
    "# smax = score_all.argmax(axis=1)\n",
    "smax = allLatent.values.argmax(axis=1)\n",
    "# score = allLatent.values[(smax,[1]*len(smax))]\n",
    "score = score_all.max(axis=1)\n",
    "clu  = scount.countMatrix(zip(smax,score),index=dfcc.index)\n",
    "# clu = dfcc.setDF(zip(clu,score))\n",
    "\n",
    "clu.columns = ['clu','score']\n",
    "cluc=clu\n",
    "# cluc = sutil.tidyBd(clu)\n",
    "\n",
    "clu.hist('score')\n",
    "\n",
    "# pyvis.latex_table_talbula\n",
    "xs,ys = sutil.meanNorm(train_data),post.locPer\n",
    "pyvis.qc_2var(xs,ys, )\n",
    "plt.title(pyutil.mse(xs,ys))\n",
    "plt.figure()\n",
    "plt.plot(post.latentScaleNorm)\n",
    "plt.ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(post.latentScaleNorm)[::-1])\n",
    "plt.ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(post.latentScaleNorm)[::-1][:25],'x')\n",
    "plt.ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(post.latentScaleNorm)[::-1][:25],'x')\n",
    "plt.ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluCount = clu.groupby('clu').apply(len).to_frame().reset_index()\n",
    "print cluCount.shape\n",
    "cluCount.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pyutil.plt.plot(post.ycat.std(axis=0))\n",
    "\n",
    "    pyutil.span(post.ycat,100)\n",
    "\n",
    "    if 'hyperDiri' in vars(post).keys():\n",
    "        pyutil.plt.plot(sorted(post.hyperDiri)[::-1])\n",
    "        plt.ylim(0., 0.2)\n",
    "except Exception as e:\n",
    "    print e\n",
    "# mdl.prior.__dict__\n",
    "\n",
    "\n",
    "%pdb  0\n",
    "\n",
    "for key in ['scale','gate','xcat_scale','xcat_scale_raw',\n",
    "            'hyperDiri'\n",
    "           ]:\n",
    "    if key not in post.__dict__.keys():\n",
    "        print ('Cannot find key:%s'%key)\n",
    "        continue\n",
    "    val = post[key]\n",
    "    print key,':',\n",
    "    if key in mdl.prior.__dict__.keys():\n",
    "        print mdl.prior[key]\n",
    "    if val.ndim ==2:\n",
    "        print val.flat[0]\n",
    "    else:\n",
    "        print val\n",
    "    print \n",
    "#     print post[key]\n",
    "\n",
    "errF = pyutil.mse\n",
    "keys = ['Age','gtype',\n",
    "        'light','ZTime_int',\n",
    "        'RunID'\n",
    "       ]\n",
    "# mcurr = mcurr0.reset_index().sort_values(keys)\n",
    "# dfcm  = dfc.reindex(columns=mcurr.DataAcc)\n",
    "\n",
    "C = sutil.meanNorm(test_data)\n",
    "# pred = reduce(np.matmul,[C,post.encoder,post.decoder])\n",
    "pred = C.dot(post.encoder)\n",
    "# pred = pred[:,1:] * post.signal_scale + pred[:,:-1] * (1- post.signal_scale)\n",
    "pred = pred.dot(post.decoder)\n",
    "# pred = l2_normalise(C.dot(post.encoder),axis=-1).dot(post.decoder)\n",
    "orig = sutil.meanNorm(C)\n",
    "\n",
    "\n",
    "latent = C.dot(post.encoder)\n",
    "# latent = l2_normalise(latent,axis=-1)\n",
    "# latent = latent / np.sum(latent**2, axis=-1,keepdims=1)**0.5\n",
    "# latent = test_data.dot(post.encoder)\n",
    "xvar = latent.std(axis=0)\n",
    "vidx = xvar.argsort()[::-1]\n",
    "latSort = latent[:,vidx]\n",
    "\n",
    "pyvis.heatmap(latent.T,cname='test')\n",
    "pyvis.heatmap(latSort.T)\n",
    "\n",
    "# err = np.mean(np.square((orig-pred)))\n",
    "err = errF(pred,orig)\n",
    "# orig = sutil.meanNorm(train_data)\n",
    "# tf.l2 = pred-orig\n",
    "pyvis.qc_2var(orig,pred)\n",
    "plt.title('err=%.3E'%err)\n",
    "fig,axs = plt.subplots(3,1,figsize=[14,8]); i=-1\n",
    "i+=1;ax=axs[i];plt.sca(ax)\n",
    "pyvis.heatmap(pred.T,ax=ax)\n",
    "i+=1;ax=axs[i];plt.sca(ax)\n",
    "pyvis.heatmap(orig.T,ax=ax)\n",
    "i+=1;ax=axs[i];plt.sca(ax)\n",
    "pyvis.heatmap( np.square(orig.T - pred.T),ax=ax)\n",
    "pyvis.plt.show()\n",
    "\n",
    "fig,axs = plt.subplots(2,1,figsize=[14,8])\n",
    "\n",
    "dec = post.decoder\n",
    "# [vidx[:-1]]\n",
    "pyvis.heatmap(post.encoder.T[vidx],cname ='test',ax=axs[0])\n",
    "pyvis.heatmap(dec, cname='test',ax=axs[1])\n",
    "\n",
    "pyvis.plt.show()\n",
    "  \n",
    "\n",
    "pyvis.plt.show()\n",
    "\n",
    "plotLatent(latSort,)\n",
    "pyvis.plt.show()\n",
    "\n",
    "# pyvis.plt.plot(xvar,post.latentScale,'x')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(post.latentScale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmd.model.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print post.encoder.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotLatent(latSort,clu=data['target'][test_ind],n = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvis.histoLine(post.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(latent.mean(axis=0))\n",
    "plt.plot(post.latent.mean(axis=0),'--')\n",
    "plt.plot(post.latMean,'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(post.latentScaleBase)\n",
    "plt.plot(np.exp(post.latentScaleBase)-1,'--')\n",
    "plt.plot(post.latentScale,'x')\n",
    "plt.ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_pca = sutil.fit_PCA(sutil.meanNorm(all_data),n_components=3).trans_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyvis.heatmap(sutil.meanNorm(test_data).T,cname = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvis.qc_2var(*sutil.meanNorm(train_data).T[4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = sutil.meanNorm(test_data)\n",
    "pcmd = sutil.fit_PCA(C=C,n_components=14,)\n",
    "if isinstance(pcmd,dict):\n",
    "    pcmd = pyutil.util_obj(**pcmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "# import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# dat = coord_tsne.T\n",
    "# dat = coord_tsne_corr.T\n",
    "dat = latSort.T\n",
    "# dat = pcmd.trans_data.T\n",
    "lab =  data['target'][test_ind]\n",
    "# dat = latent.T\n",
    "\n",
    "# dat = post.latent.T[vidx]\n",
    "# dat = coord_tsne_corr.T\n",
    "# color = None\n",
    "color = lab\n",
    "text = lab\n",
    "colorscale = 'Rainbow'\n",
    "# x, y, z = np.random.multivariate_normal(np.array([0,0,0]), np.eye(3), 200).transpose()\n",
    "x,y,z= dat[:3]\n",
    "\n",
    "# xlim = pyutil.span(x,99.)\n",
    "# ylim = pyutil.span(y,99.)\n",
    "# zlim = pyutil.span(z,99.)\n",
    "xlim = None\n",
    "ylim = None\n",
    "zlim = None\n",
    "\n",
    "\n",
    "trace1 = go.Scatter3d(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    text=lab,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=color,\n",
    "        colorscale = colorscale,\n",
    "        line=dict(\n",
    "            color='rgba(217, 217, 217, 0.14)',\n",
    "            width=0.5\n",
    "        ),\n",
    "        opacity=0.8\n",
    "    )\n",
    ")\n",
    "layout = go.Layout(  \n",
    "    scene = dict(\n",
    "    xaxis=dict(\n",
    "        range=xlim\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        range=ylim\n",
    "    ),\n",
    "    zaxis=dict(\n",
    "        range=zlim\n",
    "    )\n",
    "    ),\n",
    ")\n",
    "fig = go.Figure(data=[trace1], layout=layout)\n",
    "plotly.offline.iplot(fig, filename='simple-3d-scatter')\n",
    "plotly.offline.plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvis.heatmap(latent.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
